---
title: "final_project_markdown"
author: "Eric Lyall"
date: '2022-03-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introdution (Eric is writing this)
The paper we are reviewing is called "Experimental evolution for niche breadth in bacteriophage T4 highlights the importance of structural genes". It was the doctoral thesis for Jenny Pham at Harvard. The purpose of this paper was to analyze the evolution of T4 bacteriophage. T4 baceriophage is lytic virus which infects E.coli.

They did this by growing a  T4 bacteriophage (derived from a common ancestor) in 15 cultures of bacteria for approximately 50 generations. Each culture was passaged daily.  5 of the bacteria cultures had E.coli C, 5 had E.coli K12, and 5 had alternating populations


After 20 days, the author isolated phage population samples from each of the 15 populations and preformed whole genome sequencing on them with a coverage depth of 1000x. Then then compared the mutations from each of the samples. 

We chose this analysis because it is very similar to what one team member (Eric Lyall) will have to for the Tropini Lab this summer. This analysis also makes use of a new mutation-calling tool called breseq, which neither of us have had previous exposure to. 

#Methods: 

## Downloading the reference genome:

We need to download the reference genome to use as a comparison while searching for mutations. The reference genome can be downloaded from NCBI here: https://www.ncbi.nlm.nih.gov/nuccore/NC_000866
Following the instructions from the breseq website, we first need to make sure the "show sequence" box is selected, so that we download the sequence as well as the features:
![Accessing reference genome on GeneBank](GenBank.png)
At this point, we can click the "send to" button and download the file as a genebank file (.gb)
![Accessing reference genome on GeneBank](GenBankDownload.png)
Using scp, we can trasfer the file over to our cluster: 
```{r pressure, echo=FALSE}
#scp sequence.gb elyall_bmeg22@orca1.bcgsc.ca:/home/elyall_bmeg22/final_project/paired
```

After transferring over the file, we need to check to make sure it contains the sequence as well as the features. This can be done by opening the file, and scrolling until you see a header called "Origin". Under this should be a sequence with nucleotides. 


```{r}
#cat sequence.gb

```
![Accessing reference genome on GeneBank](view_genebank_file.png)
We have sucessfully downloaded the reference genome! 

#Mutation calling pipeline for a single sample:
We will now overview the data analysis pipeline for a single sample (SRR10323947). 
This consists of
1) downloading the fastq files from SRA
2) Running fastqc on the fastq files
3) Using trimmomatic to clean up are fastq files and remove the illumina adapters. 
4) Running fastqc again on the trimmed samples to confirm trimmmatic was sucessful
5) Running breseq to find mutations relative to the T4 bacteriophage reference genome. 
6) Using gdtools to get an annotated list of the mutations. 

After this section, we will develop a series of pipelines that does all of this together. 
## Step 1: Downloading the fastq file from SRA:

The first step is to download the sequences for each of the 15 samples from SRA. 

```{r}
#using conda to install the sra tools package
#conda install -c bioconda sra-tools

#It's important to add the split files command to get both forwards and reverse reads. 
# fastq-dump SRR10323947 --split-files 
```


#Step 2:Running fastqc on the the fastq file: 

We can use fastQC to check the quality of our files. This checks the quality socres of our sequences, and tells us if there is unexpected coverage, adapter content or unkonwn nucleotides.   
```{r}
#fastqc SRR10323947_1.fastq
```

The read quality drops off significantly near the ends of reads. This means we will have to use trimmomatic to remove some of the poor quality bases near the end of every read. This allows downstream ananlysis with breseq to only work with high quality data. 
![Base quality has significant drop off near the ends of reads](fastqc_example.png)

##Step 3: USing trimmomatic to filter the fastq file and remove illumina adapters. 
Next we can use trimmomatic to trim off the adapter sequences and poor reads near the end. The paper mentions: "Demultiplexed reads were trimmed for Nextera adapter sequences using Trimmomatic with default settings". We also have to trim off the illumina adapters from our reads, as shows in the photo below
![Adapters to get rid of](fastqc_adapters_to_trim.png)

```{r}
#conda install -c bioconda trimmomatic

#First we have to make sure the fastqc files we have are in the zipped format- this makes it faster for trimmomatic. 
#gzip *.fastq

#NExt we need to copy the illumina adapters for nextera paired-end sequencing into our working directory. These are downloaded with trimmomatic. 
#(bmeg400e_env) elyall_bmeg22@orca01:~/anaconda3/pkgs/trimmomatic-0.39-hdfd78af_2/share/trimmomatic/adapters$ cp NexteraPE-PE.fa /home/elyall_bmeg22/final_project/

#Now we can run the trimmomatic commands to remove the illumina adapters. The other parameters (sliding window, minlen, 2:40:15) are default parameters taken off the trimmomatic documentation, as the study authors did not say what paraemters they used. 

#trimmomatic PE SRR10323947_1.fastq.gz SRR10323947_2.fastq.gz SRR10323947_1.trim.fastq.gz SRR10323947_1un.trim.fastq.gz SRR10323947_2.trim.fastq.gz SRR10323947_2un.trim.fastq.gz SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15

#Below is the output of the trimmomatic command: 

#TrimmomaticPE: Started with arguments:
# SRR10323947_1.fastq.gz SRR10323947_2.fastq.gz SRR10323947_1.trim.fastq.gz SRR10323947_1un.trim.fastq.gz SRR10323947_2.trim.fastq.gz #SRR10323947_2un.trim.fastq.gz SLIDINGWINDOW:4:20 MINLEN:25 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15
#Using PrefixPair: 'AGATGTGTATAAGAGACAG' and 'AGATGTGTATAAGAGACAG'
#Using Long Clipping Sequence: 'GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG'
#Using Long Clipping Sequence: 'TCGTCGGCAGCGTCAGATGTGTATAAGAGACAG'
#Using Long Clipping Sequence: 'CTGTCTCTTATACACATCTCCGAGCCCACGAGAC'
#Using Long Clipping Sequence: 'CTGTCTCTTATACACATCTGACGCTGCCGACGA'
#ILLUMINACLIP: Using 1 prefix pairs, 4 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences
#Quality encoding detected as phred33
#Input Read Pairs: 1086157 Both Surviving: 670281 (61.71%) Forward Only Surviving: 393675 (36.24%) Reverse Only Surviving: 13161 (1.21%) #Dropped: 9040 (0.83%)
#TrimmomaticPE: Completed successfully

```

## Step 4: Running an additional fastqc to confirm the adapter sequences are removed: 
```{r}
#fastqc SRR10323947_1.trim.fastq.gz
```
You can see the tha nextera adapter content is now removed. There are still quality control concerns, but since the authors did not make any additional adjusttments, neither will we. 
![After cleaning up the adapter content](cleaned_adapters.png)
## Step 5: Running breseq to call mutations on our sample
The next step is to download and run breseq. breseq is a pipeline that is best for calling mutations on small microbial genomes. It starts by allinging the reads to a reference sequence, and then looks for consistent mismatches. 
Breseq can be run in "population mode" with the -p flag. This is used when a heterogeneous population is sequences, and one wants to find all of the possible mutations against a reference sequence. If greater than 5% of the reads at a given position mismatch, breseq reports a mutation at this position. 
breseq will report all of the mutations, their frequencies and positions. It also looks at the reading frame and determines if mutations are synonymous or non-synonymous, and identified deletions, insertions and SNP's. Using the genome annotation from the reference sequence, breseq will report what gene the mutation occurs in and the function of that gene if it's available. These features make breseq and incredibly useful tool for analyzing mutations in microbial sequences. 
```{r}

#Breseq requires bowtie and samtools to be installed first. 

#conda -c bioconda install bowtie
#conda -c bioconda install samtools

#Now installing breseq
#conda -c bioconda install breseq

#ARunning breseq on a single sample, where seqeunce.gb is our reference T4 bacteriophage sequene. 
# breseq -p -r sequence.gb -o /home/elyall_bmeg22/final_project/paired/trimmed_files/breseq_run/ SRR10323947_1.trim.fastq.gz SRR10323947_2.trim.fastq.gz
```
Let's look at some of the output files of our breseq data!

Breseq gives us summary information for each sample. This lets us know that most of our read are mapped. Breseq requires 90% of a reads length to map. 
![breseq summary information](summary_info.png)

Breseq also give a list of mutation predictions for each sample:

![breseq mutation predictions](sample_output.png)
If you click on the evidence, it will show you all of the reads mapping to that position, and highlight the exptcted mutation. 
![breseq alignment evidence](align_evidence.png)

We can see our coverage is close to 1000 base pairs on average (which is what the authors aimed to seqeunce at). Breseq highlights 
![breseq coverage example](Coverage_example.png)


#Creating pipeline to preform analysis on all 15 samples:
This section contains a combination of pipelines that will ultimately run mutation calling on all 15 of our samples


##Downloading all of the SRA names from NIH:
Making a textfile containing all of the SRA names
```{r}
#First we have to download the acession list as a txt file form NCBI
#https://www.ncbi.nlm.nih.gov/sra?term=SRP226618

#creating a .txt file containing all of the SRA #'s for each sample: 
nano SRA_seqs.txt #We then copy paste all of the SRA #'s names into this file 

```

##Creating a pipeline that downloads fastq files and runs fastQC on them
Now, we are going to generate a pipline that downloads the fastQ files, runs fastQC on each of these.
Normally we would use a job scheduler to do this, but apparently our server can't do this.
So we will used Dr. De Boer's script which runs a script for each line in an input file
The script is here: (https://raw.githubusercontent.com/BMEGGenoInfo/Assignments/main/Assignment_2/runTheseJobsSerially.sh

```{r}
#Downloading Carl's script: 

#wget https://raw.githubusercontent.com/BMEGGenoInfo/Assignments/main/Assignment_2/runTheseJobsSerially.sh

#Getting permissions to run it:

#chmod +x runTheseJobsSerially.sh

#Creating a pipeline called down_trim_pipeline.sh that downloads files from NCBI, runs fastQC and then runs trimmomatic on them. 

#First we make the name of the pipeline: 
#nano down_trim_pipeline.sh

#Then we get permission on it

#chmod +x down_trim_pipeline.sh

#Then we run it!

#./runTheseJobsSerially.sh ./pipelines/down_trim_pipeline.sh SRA_seqs.txt

#Then, we start adding to it!


#!/bin/bash


#set -e # this makes the whole script exit on any error.
#sample=$1
#mkdir -p fastq_samples # making a directory to add the fastq files
#mkdir -p fastqc_files #making a directory for fastqc_files
#mkdir -p downtrim_logfiles
##Now, going to run the pipeline: 

#echo running pipeline for $sample
#if [ ! -e downtrim_logfiles/$sample.fastq.done ] 
#then
#        echo Downloading $sample
#       #Command download sample:
#        fastq-dump $sample --split-files --outdir fastq_samples/
#        touch downtrim_logfiles/$sample.fastq.done #add a flag to say fastq downloaded.
#else
#        echo Already performed fastqc of $sample
#        fi
#if [ -e downtrim_logfiles/$sample.fastq.done ] #if the fastq is done,do fastqc
#then
#        echo Running fastqc with $sample
#        mkdir fastqc_files/$sample
#        fastqc $fastq_samples/{sample}_1.fastq --outdir fastqc_files/$sample/
#        fastqc $fastq_samples/{sample}_2.fastq --outdir fastqc_files/$sample/
#        touch downtrim_logfiles/$sample.fastqc.done
#else
#        echo: FastQC was not made sucessfully.
#        fi

```

#Making a trimmomatic pipeline for all samples
We found no additiona concerns beyone the ones mention with our pilot sample in the fastQC.
Before running a trimmomatic pipeline on all of the samples, we have to gzip the files. 
Now we can make a pipeline to trim all the samples: 

```{r}
#gzip fastq_samples/*.fastq

#Making the name of the trimmomatic pipeline:
nano pipelines/trimmomatic.sh
chmod +x trimmomatic.sh

#running the pipeline: 
#./runTheseJobsSerially.sh ./pipelines/trimmomatic.sh SRA_seqs.txt
        

```

Below is the code for our trimmomatic pipeline

```{r}
#!/bin/bash
set -e # this makes the whole script exit on any error.
sample=$1
mkdir -p trimmomatic_files
if [ ! -e downtrim_logfiles/$sample.trim.done ]
then
        mkdir trimmomatic_files/$sample
        #trimmomatic PE $fastq_samples/${sample}_1.fastq.gz fastq_samples/${sample}_2.fastq.gz trimmomatic_files/$sample/${sample}_1.trim.fastq.gz trimmomatic_files/$sample/${sample}_1un.trim.fastq.gz trimmomatic_files/$sample/${sample}_2.trim.fastq.gz trimmomatic_files/$sample/${sample}_2un.trim.fastq.gz SLIDINGWINDOW:4:15 MINLEN:25 LEADING:3 TRAILING:3 ILLUMINACLIP:NexteraPE-PE.fa:2:40:15

        touch downtrim_logfiles/$sample.trimmed.done
else
        echo:trimmomatic failed
        fi
```

##Making a pipeline to run breseq
This pipeline could have been attached to the trimmomatic pipeline, but I prefer to run fastQC on some of the trimmed samples to ensure the trimmins is successful. 

```{r}
#Now we make a pipeline to run breseq:
nano pipelines/breseq_pipe.sh
chmod +x breseq_pipe.sh
#Anddd running the pipeline
./runTheseJobsSerially.sh ./pipelines/breseq_pipe.sh SRA_seqs.txt

#The pipeline starts below: 

#!/bin/bash
set -e # this makes the whole script exit on any error.
sample=$1
mkdir -p breseq_files
if [ -e downtrim_logfiles/$sample.trimmed.done ]
then
        #Going to run breseq on it
        mkdir -p breseq_files/$sample
        #Running the breseq command:
        # breseq -p -r sequence.gb -o /home/elyall_bmeg22/final_project/breseq_files/$sample/ trimmomatic_files/$sample/${sample}_1.trim.fastq.gz trimmomatic_files/$sample/${sample}_2.trim.fastq.gz
        touch downtrim_logfiles/$sample.breseq.done
else
        echo:breseq failed
        fi
```


#breseq mutation calling has finished!
Typically at this point we would run a single line of breseq code that would filter all the mutations we found against the ancestral sequence.

However, the author's didn't actually share the data for the ancestral sample, which is supposed to be compared against the experimental sample, and have common mutations filtered out. 
This is a bit of an issue for us- keeping all of these mutations in, most of which are from the ancestor, makes it difficult compare data against the paper, and focus on the mutations which are important. 
As a proxy for filtering against the ancestral sequence, we are going to filter against the final list of mutations the authors have provided in their supplementary table. 

We discussed these changes with Carl and he said we would not lose difficultly score points here. 


Defining which sample is what- this is what Eric has found so far:  
SRR 61 = 55D18R1 # E coli K12
SRR 60 = 55D18R2 #E coli K12
SRR 59 = CD18R1 #E coli C
SRR 58 =CD18R2 #E coli C
SRR 57 = CD18R3 #E coli C
SRR 56 = CD18R4 #E coli C
SRR 55 = CD18R5 #E coli C
SRR 54 = 55D18R3 # E coli K12
SRR 53 = 55D18R4 # # E coli K12
SRR 52 = 55D18R5 # E coli K12
SRR 51 = 55CD18R1  # alternating e.coli C and K12
SRR 50 = 55CD18R2 # alternating e.coli C and K12
SRR 49 =55CD18 R3 # alternating e.coli C and K12
SRR 48 = 55CD18R4 # alternating e.coli C and K12
SRR 47 = 55CD18R5 # alternating e.coli C and K12


#Annotating our mutations & filtering against the supplementary table: (done)
To get more detail on our mutations, we can used the ANNOTATE function from breseq's gdtools 
This creates an annotated file that adds detail to each mutation found, including the type (e.g SNP), and whether is synonymous or non-synonymous.
```{r}
 
#gdtools ANNOTATE -o annotated_all.tsv -f TSV -r reference_seq.gb 47_output.gd 48_output.gd 49_output.gd 50_output.gd 51_output.gd 52_output.gd 53_output.gd 54_output.gd 55_output.gd 56_output.gd 57_output.gd 58_output.gd 59_output.gd 60_output.gd 61_output.gd

#Uploading annotated mutations from a tsv file:: 
all_ann <- as.data.frame(read.table (file = 'annotated_all.tsv', sep = '\t', header = TRUE))

#loading up the supplementary table: 
library(openxlsx)
mutation_xl <- read.xlsx("Supplementary table 2a & 2b.xlsx",sheet = 1)
mutation_df <- as.data.frame(mutation_xl)

#Filtering out the mutation in all_ann that are not in the supplementary files. This is our stand-in for not having the ancestral sequence. 
library(tidyverse)
filtered_all_ann <- filter(all_ann, position %in% mutation_df$position )
nrow(filtered_all_ann)
```

In total we have 192 surviving mutations, compared to the 174 reported in the paper. This means our analysis is largely successful!

This is much better than what we had before filtering, which was 3197 mutations (most of which are probably from the ancestor)

This means many of the mutations were shared between our data and the paper's data. 
We may have more mutations because the there could be mutations that we have (ancestral or otherwise) which share the same position. As we have no way of 
distinguishing these, we will leave them in for our analysis


#Finding the number of unique mutations: (unfinished)- Jake try this if you want, but it's a lower priority
```{r}

#Jake you can try this if you want. If you can somehow do the above filtering on a gd file directly, you can then do gdtools COMPARE, grab the html file and work from there. I'm not great at filtering shit in bash
#ONce you got the compare file use the code below. Alternatively, you can just hack at the filtered_all_ann dataframe & look for isolated mutations. Be careful thoug- sometimes there can be two types or mutations at a position.  
sub_mutation_df <- mutation_df[c(3:17)]
#Now we can transpose the dataframe: 
trans_sub_mut_df <- data.frame(t(sub_mutation_df))
#Now we can count the number of columns with only one element (representing only one sample with a mutation) in that row:
trans_cols <- colnames(trans_sub_mut_df)
unique_mutations <- 0
for(name_of_col in trans_cols)
{
        if((15-sum(is.na(trans_sub_mut_df[name_of_col])))== 1){
                unique_mutations <- unique_mutations +1
        }
        
}

```


#Annotating our mutation list with functional gene categories (done)
Now we are going to further annotate our mutation list with the gene functional categories. The authors of this paper took functional gene categories from a paper by Miller et al. We've downloaded these functional gene categories and will used them for annotation.
```{r}
#Adding a column with functional categories.

#First we have to upload each functional category and their associated genes. These designations are taken from the a paper by Miller et al, which was used in this study. 

library(openxlsx)
func_des <- read.xlsx("Supplementary table 2a & 2b.xlsx",sheet = 'melt_cat_genes')
func_des_df <- as.data.frame(func_des)

#Now, we can annotate all of our mutation with their matching functional designation. 
#If no functional designation is found, we will label it as unknown

#we are going to filter through each gene, and assign a gene designation to it:
all_genes <- filtered_all_ann$gene_name
all_genes_func <- c()
for(gene in all_genes)
{
        r <- which(func_des_df$gene == gene)
        if(length(r)==0){
                all_genes_func <- c(all_genes_func,"unknown")
        }
        else{
                all_genes_func <- c(all_genes_func,func_des_df$function_cat[r])
        }
                
}

#Adding the vector containing all the gene functional designations to our datframe
filtered_all_ann$gene_function <- all_genes_func
```


#Calculating mutations per functional category: (done)
Now we can start looking at mutations as thy relate to functional categories: 

```{r}
#Finding the number of mutations per functional category:
library(tibble)
mut_per_func <- filtered_all_ann %>% group_by(gene_function) %>% summarise(n=n()) %>% arrange(desc(n))
library(ggplot2)
ggplot(mut_per_func, aes(x="",y=n,fill = gene_function))+ geom_bar(width = 1, stat = "identity")


#Finding the number of higher-frequency mutations (greater than 50%) per functional category:
high_freq <- filtered_all_ann %>% filter(frequency > .5)
high_f_mut_func <- high_freq %>% group_by(gene_function) %>% summarise(n=n()) %>% arrange(desc(n))
ggplot(high_f_mut_func, aes(x="",y=n,fill = gene_function))+ geom_bar(width = 1, stat = "identity")


```

#Comparing mutations by type (unfinished) Jake do this
```{r}
#JAKE DO THIS!!

#Getting the total number of mutations

nrow(filtered_all_ann)
#There are 190 mutations in total
x = table(filtered_all_ann$type)
pie(x)

#Breaking down the type of mutations by category: % of intergenic mutations, % of indel mutations, % of SNP mutations, % of xNP's

#Showing this in a pi chart

#Looking at specifically the SNP mutations to find out how many are synonymous, and how many are non-synonymous, and how many are integenic

#Show this in a pi chart

```


#Calculating relative mutation rates (in progress)

The next task is to compare the relative mutation rates across each functional category. A mutation rate is defined as the # of mutations / size of functional category (in BP). 
The paper used functional catagories taken from the 2003 Miller et al. paper
We downloaded a list of T4 genes, and a list of the genes in each functional catagory from Miller's paper. 

We first need to find the size of each functional category in base pairs. This size will allow us to calculate the mutation rate. 
```{r}

#Downloading the a list of T4 genes and their sizes from the Miller et al. paper into a dataframe
t4_genes <- read.xlsx("Supplementary table 2a & 2b.xlsx",sheet = 'T4_genes')

#we are going to add a new column to the dataframe func_des_df that containes the gene length. 
#Some genes have multipl exons- in this case we will add them up
gene_length <- c()

#Iterating through all of the genes in our functionl categoreis from Miller et al.
for(gene in func_des_df$gene){
        r <- which(t4_genes$gene == gene) #getting a list of rows with the gene name
        #If the gene isn't found, append a length of zero and print the gene for a manual check to see if it truly does not exist
        if(length(r)==0){ 
                gene_length <- c(gene_length,0)
                print("Gene not found")
                print(gene)
        }
        else{ #If the gene is found
                #There may be multiple gene exons with the same name, will add lengths
                len <- 0
                for(i in r){
                       len <- len + t4_genes$length[i] 
                }
                gene_length <- c(gene_length,len) #Append the total gene length to vector
        }
}
#Adding this vector to the functional designation dataframe
func_des_df$gene_length <- gene_length 

```


Now we can get the mutation rate for each sample across each functional category. This will allow us to preform an anova to find the effect of functional category and sample population (E.coli C, E.coli K12, alternating) of the mutation rate

#Jake- we need to make this into a function and run it on all mutations, synonymous mutations (SNP's only), and non-synonymous (SNP's only)

```{r}
#We will start by making a dataframe where each column is a fucntional category, each row is a sample and values are # of mutations: 
#We only need to work with sample names & gene functions here, so we can remove the other columns:
name_gene_fcn_df <- filtered_all_ann[c("title","gene_function")] 

#Creating an empty dataframe no # mutations per functional category. 
n_mut_per_fcn_cat_df <- data.frame(matrix(ncol = 12, nrow = 15)) 

#Assigning each functional category to the column names
colnames(n_mut_per_fcn_cat_df) <- c(unique(func_des_df$function_cat),"unknown")

#Assinging each sample to the rownames: 
rownames(n_mut_per_fcn_cat_df) <- c(unique(name_gene_fcn_df$title))

#Filling this dataframe with 0's as a default:
n_mut_per_fcn_cat_df[is.na(n_mut_per_fcn_cat_df)] <- 0



#Getting a summary of the # of mutations per each functional category in our experiment
fcn_breakdown <- name_gene_fcn_df  %>% group_by(title,gene_function) %>% summarise(n=n())

#Adding this data into the n_mut_per_fcn_cat_df
for(r in 1:nrow(fcn_breakdown)){
        n_mut_per_fcn_cat_df[fcn_breakdown$title[r],fcn_breakdown$gene_function[r]] <- fcn_breakdown$n[r]
}

#Then, we will normalize each column to the number of nucleotides in each functional category: 

#Getting a list of the category names: 
cat_names <- colnames(n_mut_per_fcn_cat_df)

#For every category name, find the length of the functional category in base pairs. Then will will divide the sample mutations in a category by this number to get the "mutation rate" (# of mutation in a category / size of category in BP)

for(cat in cat_names){
        n_mut_per_fcn_cat_df[cat] <- n_mut_per_fcn_cat_df[cat]/ sum((func_des_df %>% filter(function_cat == cat))$gene_length)
}

#We are going to discard the unknown mutation columns from our analysis, because we can't normalize this data to find a mutation rate( the number of unknown genes is , unsurprisingly, unknown)
n_mut_per_fcn_cat_df <- select(n_mut_per_fcn_cat_df,-unknown)

#Now running the ANOVA
#install.packages('rcompanion)
library(rcompanion)

#help("scheirerRayHare")
#we need to run one of these

#First let's try multing this
library(reshape2)
library(vctrs)
library(dplyr)

#Melting the dataframe in preparation for an anova:
melted_mut_fcn_catdf <- melt(n_mut_per_fcn_cat_df)

#Renaming the columns to something we can understand:
melted_mut_fcn_catdf <- melted_mut_fcn_catdf %>% rename(functional_category = 1, mutation_rate = 2)


#Now making a vector containing the population designations: 
bact_pop <- vec_rep(c(rep("E.coli K12",2), rep("E.coli C", 5), rep("E.coli K12",3), rep("Alternating",5)),ncol(n_mut_per_fcn_cat_df))

melted_mut_fcn_catdf$bact_pop <- bact_pop #Adding the bacterial population to the dataframe

scheirerRayHare(mutation_rate ~ functional_category + bact_pop, data = melted_mut_fcn_catdf)

```

Now we have a dataframe containing mutations rates for each functional category as a column with samples as each rows. 
We will then do a ANOVA to determine which the effect of sample population (whether the sample evolved with Ecoli C, K12, or mixed), functional category or the interaction between the two on the mutation rate. 
The paper used an SRH non-parametric two-way ANOVA for this analysis, as the data is not normally distributed. 
```{r}



```


#Plotting mutations across the genome: Jake- can you make this look more like the paper's figure? Add some horizontal lines, label which one is which replicate, make sure we have the same categories if possible, do the empty / filled triangles?
Our last task will be to graph the mutations for each sample across then entire genome length. This will tell us if there's any similarity between samples, and we can also compare against the original figure here. 
```{r}
#We are going to try and do this with a scatter plot, using the x- axis as position of the mutation in the genome. We will make the y-axis a different fixed number for each sample. 

#First we will make a dictionary with y-axis values for each of the sample names: 
y_axis_dict <- c("47_output" = 5, "48_output" = 10, "49_output" = 15, "50_output" =20, "51_output" = 25, "52_output"= 30, "53_output" = 35, "54_output" = 40, "55_output" =55 , "56_output" =60 , "57_output"= 65, "58_output"= 70 , "59_output"= 75 , "60_output" = 45, "61_output" =50 )

#Now we are going to add a new column to the "filtered_all_ann" dataframe which contains the y-axis value corresponding to each sample name. 
mutation_y_axis_vals <- c()
output_names <- filtered_all_ann$title
for(output_name in output_names){
  y_val <- y_axis_dict[output_name]
  mutation_y_axis_vals <- c(mutation_y_axis_vals,y_val)
}
filtered_all_ann$y_ax_val <- mutation_y_axis_vals #Adding this to our mutation dataframe


#Now we will attempt to maake a scatterplot with all the mutations: 
library(ggplot2)
ggplot(filtered_all_ann, aes(x=position,y=y_ax_val, shape = mutation_category, color = gene_function)) + geom_point()

```



#Conclusion: